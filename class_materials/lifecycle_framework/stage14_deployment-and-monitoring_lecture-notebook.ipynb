{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a344603",
   "metadata": {},
   "source": [
    "# Stage 14 — Deployment & Monitoring (Conceptual Overview)\n",
    "\n",
    "This notebook demonstrates **conceptual** patterns for logging and simple checks. No real infrastructure.\n",
    "\n",
    "**Layers to monitor:** Data · Model · System · Business\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c790f44b",
   "metadata": {},
   "source": [
    "## 0. Imports & Setup\n",
    "- We use only standard library to keep focus on concepts.\n",
    "- Output files are written to a temporary folder (`/tmp/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import random, time, csv, json, math, statistics\n",
    "\n",
    "BASE = Path('./tmp/stage14_demo')\n",
    "BASE.mkdir(parents=True, exist_ok=True)\n",
    "METRICS_CSV = BASE / 'metrics.csv'\n",
    "if not METRICS_CSV.exists():\n",
    "    with METRICS_CSV.open('w', newline='') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['ts','name','value','layer','model_version','window','context'])\n",
    "print(f'Writing metrics to: {METRICS_CSV}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656cdf8b",
   "metadata": {},
   "source": [
    "## 1. Risk → Metric Mapping (conceptual)\n",
    "\n",
    "| Risk | Metric | Layer |\n",
    "|---|---|---|\n",
    "| Schema change | Schema hash mismatch | Data |\n",
    "| Null spike | % nulls by column | Data |\n",
    "| Concept drift | Rolling MAE/AUC | Model |\n",
    "| Latency spike | p95 latency (ms) | System |\n",
    "| Silent degradation | Calibration / business KPI shift | Business |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8adcc61",
   "metadata": {},
   "source": [
    "## 2. Minimal Metric Logger\n",
    "Append a metric row to `metrics.csv` with ISO timestamp and a small JSON context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47377669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metric(name, value, *, layer, model_version='v1', window='1m', **ctx):\n",
    "    row = [\n",
    "        datetime.utcnow().isoformat(timespec='seconds') + 'Z',\n",
    "        name,\n",
    "        float(value),\n",
    "        layer,\n",
    "        model_version,\n",
    "        window,\n",
    "        json.dumps(ctx)\n",
    "    ]\n",
    "    with METRICS_CSV.open('a', newline='') as f:\n",
    "        csv.writer(f).writerow(row)\n",
    "    return row\n",
    "\n",
    "# quick smoke test\n",
    "log_metric('job_success', 1.0, layer='system', window='1d', job='nightly_batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ca3ded",
   "metadata": {},
   "source": [
    "## 3. Simulate Predictions & Rolling MAE\n",
    "We simulate a prediction task and compute a rolling error to log as a model metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b801b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "y_true, y_pred = [], []\n",
    "for t in range(120):\n",
    "    y = random.random()  # ground truth in [0,1]\n",
    "    # simulate a model that slowly degrades after t>80\n",
    "    noise = 0.05 if t <= 80 else 0.15\n",
    "    pred = min(1.0, max(0.0, y + random.uniform(-noise, noise)))\n",
    "    y_true.append(y); y_pred.append(pred)\n",
    "    if t >= 19:\n",
    "        window_true = y_true[t-19:t+1]\n",
    "        window_pred = y_pred[t-19:t+1]\n",
    "        mae = sum(abs(a-b) for a,b in zip(window_true, window_pred))/20\n",
    "        row = log_metric('rolling_mae', mae, layer='model', window='20obs', step=t)\n",
    "        # fake latency (ms)\n",
    "        latency = random.randint(60, 160) if t <= 80 else random.randint(120, 300)\n",
    "        log_metric('p95_latency_ms', latency, layer='system', window='1m', step=t)\n",
    "row[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21665678",
   "metadata": {},
   "source": [
    "## 4. Simple Threshold Checks\n",
    "Toy rules: if MAE > 0.12 or p95 latency > 250ms → alert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a71b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "RULES = {\n",
    "    'rolling_mae': {'op': '>', 'value': 0.12, 'severity': 'warning'},\n",
    "    'p95_latency_ms': {'op': '>', 'value': 250, 'severity': 'warning'}\n",
    "}\n",
    "\n",
    "def check_threshold(name, value):\n",
    "    r = RULES.get(name)\n",
    "    if not r:\n",
    "        return {'status': 'ok'}\n",
    "    op = r['op']; thresh = r['value']\n",
    "    ok = (value < thresh) if op == '>' else (value > thresh)\n",
    "    return {'status': 'ok' if ok else 'alert', 'rule': r}\n",
    "\n",
    "# example\n",
    "check_threshold('rolling_mae', 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a75938",
   "metadata": {},
   "source": [
    "## 5. Batch Scoring Skeleton (pseudocode)\n",
    "\n",
    "`\n",
    "def nightly_batch():\n",
    "    data = load_inputs()\n",
    "    preds = model.predict(data)\n",
    "    write_output(preds)\n",
    "    # monitoring artifacts\n",
    "    log_metric('row_count', len(data), layer='data', window='1d')\n",
    "    drift = compute_simple_drift(data)  # e.g., population mean shift\n",
    "    log_metric('feature_mean_shift', drift['amount'], layer='data', feature=drift['feature'])\n",
    "`\n",
    "\n",
    "Key takeaway: even simple logs provide early warning signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd3bad",
   "metadata": {},
   "source": [
    "## 6. Dashboard Contents (conceptual)\n",
    "- **Data**: freshness minutes, %nulls, schema hash\n",
    "- **Model**: rolling MAE/AUC, calibration, stability index\n",
    "- **System**: p95 latency, error rate, availability\n",
    "- **Business**: approval rate, bad-rate, revenue per decision\n",
    "- **Runbook**: on-call, remediation steps, suppression windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce9b9e",
   "metadata": {},
   "source": [
    "## 7. Handoff README — What to Include\n",
    "- Endpoint(s) & auth\n",
    "- Data contracts & schema versioning\n",
    "- Model versioning & rollback\n",
    "- Monitoring metrics & alert thresholds\n",
    "- Ownership: contacts, escalation\n",
    "- Change log\n",
    "\n",
    "> This course does **not** require real deployment; we prepare you to collaborate with platform teams."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
