{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7ead24",
   "metadata": {},
   "source": [
    "# Stage 15 â€” Orchestration & System Design (Conceptual Overview)\n",
    "This notebook demonstrates orchestration **concepts**: modular tasks, explicit I/O, logging, checkpoints, a tiny DAG runner, and a CLI-friendly entrypoint.\n",
    "\n",
    "**Note:** We are *not* teaching Airflow/Prefect. We simulate the ideas in pure Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abdeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import argparse, json, logging, time, sys\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Callable\n",
    "\n",
    "BASE = Path.cwd() / 'stage15_demo'\n",
    "DATA = BASE / 'data'\n",
    "LOGS = BASE / 'logs'\n",
    "REPORTS = BASE / 'reports'\n",
    "for p in [DATA, LOGS, REPORTS]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(levelname)s | %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "        logging.FileHandler(LOGS / 'pipeline.log')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info('Folders ready at %s', BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb2a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TaskResult:\n",
    "    name: str\n",
    "    ok: bool\n",
    "    output_path: str | None = None\n",
    "    message: str = ''\n",
    "\n",
    "def write_json(path: Path, obj: dict):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(json.dumps(obj, indent=2))\n",
    "\n",
    "def checkpoint_exists(path: Path) -> bool:\n",
    "    return path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc906e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_prices(output_path: Path) -> TaskResult:\n",
    "    logger.info('[ingest_prices] start')\n",
    "    time.sleep(0.1)\n",
    "    data = {'timestamp': datetime.utcnow().isoformat(), 'prices': [100.0, 101.2, 99.8, 102.1]}\n",
    "    write_json(output_path, data)\n",
    "    logger.info('[ingest_prices] wrote %s', output_path)\n",
    "    return TaskResult('ingest_prices', True, str(output_path))\n",
    "\n",
    "def clean_prices(input_path: Path, output_path: Path) -> TaskResult:\n",
    "    logger.info('[clean_prices] start')\n",
    "    raw = json.loads(Path(input_path).read_text())\n",
    "    prices = [p for p in raw['prices'] if p is not None]\n",
    "    cleaned = {'timestamp': raw['timestamp'], 'prices': prices, 'mean': sum(prices)/len(prices)}\n",
    "    write_json(output_path, cleaned)\n",
    "    logger.info('[clean_prices] wrote %s', output_path)\n",
    "    return TaskResult('clean_prices', True, str(output_path))\n",
    "\n",
    "def fit_dummy_model(clean_path: Path, model_path: Path) -> TaskResult:\n",
    "    logger.info('[fit_dummy_model] start')\n",
    "    clean = json.loads(Path(clean_path).read_text())\n",
    "    model = {'type': 'mean_predictor', 'mean': clean['mean']}\n",
    "    write_json(model_path, model)\n",
    "    logger.info('[fit_dummy_model] wrote %s', model_path)\n",
    "    return TaskResult('fit_dummy_model', True, str(model_path))\n",
    "\n",
    "def generate_report(model_path: Path, report_path: Path) -> TaskResult:\n",
    "    logger.info('[generate_report] start')\n",
    "    model = json.loads(Path(model_path).read_text())\n",
    "    text = f'Report generated at {datetime.utcnow().isoformat()}\\nModel: {model}\\n'\n",
    "    report_path.write_text(text)\n",
    "    logger.info('[generate_report] wrote %s', report_path)\n",
    "    return TaskResult('generate_report', True, str(report_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAG: Dict[str, List[str]] = {\n",
    "    'ingest': [],\n",
    "    'clean': ['ingest'],\n",
    "    'fit': ['clean'],\n",
    "    'report': ['fit']\n",
    "}\n",
    "\n",
    "def topo_sort(dag: Dict[str, List[str]]) -> List[str]:\n",
    "    pending = {k: set(v) for k, v in dag.items()}\n",
    "    done = []\n",
    "    while pending:\n",
    "        ready = [k for k, deps in pending.items() if not deps]\n",
    "        if not ready:\n",
    "            raise ValueError('Cycle detected or unsatisfied deps')\n",
    "        for r in ready:\n",
    "            done.append(r)\n",
    "            pending.pop(r)\n",
    "            for deps in pending.values():\n",
    "                deps.discard(r)\n",
    "    return done\n",
    "\n",
    "def retry(n_tries=3, delay=0.2):\n",
    "    def wrap(fn: Callable, *args, **kwargs):\n",
    "        for i in range(1, n_tries+1):\n",
    "            try:\n",
    "                return fn(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                logger.exception('Attempt %s failed: %s', i, e)\n",
    "                time.sleep(delay * i)\n",
    "        raise RuntimeError(f'Task failed after {n_tries} attempts')\n",
    "    return wrap\n",
    "\n",
    "def run_pipeline(skip_existing=True):\n",
    "    ingest_out = DATA / 'prices_raw.json'\n",
    "    clean_out = DATA / 'prices_clean.json'\n",
    "    model_out = DATA / 'model.json'\n",
    "    report_out = REPORTS / 'report.txt'\n",
    "\n",
    "    order = topo_sort(DAG)\n",
    "    logger.info('Execution order: %s', order)\n",
    "\n",
    "    if not (skip_existing and checkpoint_exists(ingest_out)):\n",
    "        retry()(ingest_prices, ingest_out)\n",
    "    else:\n",
    "        logger.info('[ingest] checkpoint hit: %s', ingest_out)\n",
    "\n",
    "    if not (skip_existing and checkpoint_exists(clean_out)):\n",
    "        retry()(clean_prices, ingest_out, clean_out)\n",
    "    else:\n",
    "        logger.info('[clean] checkpoint hit: %s', clean_out)\n",
    "\n",
    "    if not (skip_existing and checkpoint_exists(model_out)):\n",
    "        retry()(fit_dummy_model, clean_out, model_out)\n",
    "    else:\n",
    "        logger.info('[fit] checkpoint hit: %s', model_out)\n",
    "\n",
    "    retry()(generate_report, model_out, report_out)\n",
    "    return str(report_out)\n",
    "\n",
    "logger.info('Pipeline ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32539c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    parser = argparse.ArgumentParser(description='Stage15 pipeline demo')\n",
    "    parser.add_argument('--run-all', action='store_true', help='Run the full pipeline')\n",
    "    parser.add_argument('--no-skip', action='store_true', help='Ignore checkpoints')\n",
    "    args = parser.parse_args(argv)\n",
    "    if args.run_all:\n",
    "        out = run_pipeline(skip_existing=not args.no_skip)\n",
    "        logger.info('Report at: %s', out)\n",
    "    else:\n",
    "        logger.info('Use --run-all to execute the full demo pipeline.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(['--run-all'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
