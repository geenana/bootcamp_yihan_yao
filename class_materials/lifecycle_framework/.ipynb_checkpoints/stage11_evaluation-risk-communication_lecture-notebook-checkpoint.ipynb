{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90af611",
   "metadata": {},
   "source": [
    "# Stage 11: Evaluation & Risk under Assumptions\n",
    "*Applied Financial Engineering Lifecycle (Aug 25, Mon)*\n",
    "\n",
    "## Objectives\n",
    "- Evaluate model predictions under uncertainty\n",
    "- Identify how assumptions affect results\n",
    "- Compare scenarios (missing data, model form, distributional assumptions)\n",
    "- Communicate risk and sensitivity clearly to stakeholders\n",
    "- Use bootstrap and CI visualizations to illustrate uncertainty\n",
    "\n",
    "**Mindset:** Credibility over confidence. Ask: *What if our assumptions are wrong?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc28f19",
   "metadata": {},
   "source": [
    "## Teaching Tip:\n",
    "Introduce this stage with a discussion: \"Why do assumptions matter?\" Use a real-world example of risk misestimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "np.random.seed(11)\n",
    "plt.rcParams['figure.figsize'] = (8, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367cb7fe",
   "metadata": {},
   "source": [
    "## Data: Load or Generate\n",
    "Check for existing CSV; if missing, generate synthetic data with some NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ced682",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('data')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "csv_path = data_dir / 'data_stage11_eval_risk.csv'\n",
    "\n",
    "if csv_path.exists():\n",
    "    df = pd.read_csv(csv_path)\n",
    "else:\n",
    "    x = np.linspace(0, 10, 80)\n",
    "    y = 2.5 * x + 3 + np.random.normal(0, 3, size=x.size)\n",
    "    df = pd.DataFrame({'x': x, 'y': y})\n",
    "    # Introduce random missing values\n",
    "    df.loc[np.random.choice(df.index, 5), 'y'] = np.nan\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4a66bd",
   "metadata": {},
   "source": [
    "## Visual Check for Missing Values\n",
    "Inspect data quality before modeling.\n",
    "\n",
    "### Teaching Tip:\n",
    "Highlight to students that missing data is common and must be handled deliberately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdae5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing values:', df.isna().sum().to_dict())\n",
    "plt.scatter(df['x'], df['y'])\n",
    "plt.title('Scatter with Missing Values')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f5530",
   "metadata": {},
   "source": [
    "## Scenario 1: Fill Method Assumptions\n",
    "üìå Compare Mean Fill vs Median Fill vs Dropping Missing Data\n",
    "\n",
    "### Teaching Tip:\n",
    "Discuss with students how choice of fill method represents an assumption about the missing data mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8dbcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df.copy()\n",
    "print(df['y'].mean())\n",
    "df_mean['y'] = df_mean['y'].fillna(df['y'].mean())\n",
    "\n",
    "df_med = df.copy()\n",
    "print(df['y'].median())\n",
    "df_med['y'] = df_med['y'].fillna(df['y'].median())\n",
    "\n",
    "print(np.nan)\n",
    "df_drop = df.dropna()\n",
    "print(\"\")\n",
    "\n",
    "def fit_lin(d):\n",
    "    m = LinearRegression().fit(d[['x']], d['y'])\n",
    "    return float(m.coef_[0]), float(m.intercept_)\n",
    "\n",
    "s_mean, i_mean = fit_lin(df_mean)\n",
    "s_med, i_med = fit_lin(df_med)\n",
    "s_drop, i_drop = fit_lin(df_drop)\n",
    "\n",
    "print('Mean Fill:', s_mean, i_mean)\n",
    "print('Median Fill:', s_med, i_med)\n",
    "print('Drop NA:', s_drop, i_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195d017",
   "metadata": {},
   "source": [
    "üìå **Observation:** Different fill strategies result in slightly different slopes and intercepts.\n",
    "- Mean fill pulls toward the average.\n",
    "- Median fill resists skew.\n",
    "- Dropping reduces sample size.\n",
    "\n",
    "üëâ Communicate: *‚ÄúHandling missing data changes risk conclusions.‚Äù*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe238be",
   "metadata": {},
   "source": [
    "## Scenario 2: Linear vs Polynomial Regression\n",
    "üìå Compare model forms and their impact on conclusions\n",
    "\n",
    "### Teaching Tip:\n",
    "Encourage students to visualize both linear and nonlinear fits to illustrate overfitting vs underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e66214",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mean[['x']]\n",
    "y = df_mean['y']\n",
    "\n",
    "lin = LinearRegression().fit(X, y)\n",
    "poly = make_pipeline(PolynomialFeatures(2), LinearRegression()).fit(X, y)\n",
    "\n",
    "plt.scatter(X, y, alpha=0.5)\n",
    "plt.plot(X, lin.predict(X), label='Linear')\n",
    "plt.plot(X, poly.predict(X), label='Polynomial (deg=2)')\n",
    "plt.legend()\n",
    "plt.title('Model Assumption Comparison')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182c38d",
   "metadata": {},
   "source": [
    "üìå **Observation:** Polynomial captures curvature but may overfit.\n",
    "üëâ Stakeholders must understand that conclusions can shift with a shift in models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c593b7bb",
   "metadata": {},
   "source": [
    "## Scenario 3: Gaussian vs Bootstrapped Confidence Intervals\n",
    "üìå Compare distributional assumptions for prediction uncertainty\n",
    "\n",
    "### Teaching Tip:\n",
    "Illustrate that Gaussian CI can underestimate risk in presence of fat tails; bootstrap provides a more robust alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae58ab-a7e6-4996-a5d2-2b8a58d045e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48042da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on full X\n",
    "y_hat = lin.predict(X)\n",
    "resid = y - y_hat\n",
    "sigma = resid.std()\n",
    "\n",
    "# Gaussian CI (over X, not confidence interval of X itself)\n",
    "# Builds a 95% confidence interval using ¬±1.96 √ó standard deviation.\n",
    "# Assumes prediction errors are normally distributed.\n",
    "# This is a quick and theoretical method ‚Äî doesn't use resampling.\n",
    "ci_gauss = (y_hat - 1.96*sigma, y_hat + 1.96*sigma)\n",
    "\n",
    "# Bootstrap CI\n",
    "boot_preds = []\n",
    "for _ in range(500):\n",
    "    #Take a bootstrapped sample of rows from df_mean: a full-size sample with replacement.\n",
    "    #Introduces variation like a real-world sampling error.   \n",
    "    # fac=1 => 100% of the original dataset size, (but with replacement)\n",
    "    sample = df_mean.sample(frac=1, replace=True)\n",
    "    m = LinearRegression().fit(sample[['x']], sample['y'])\n",
    "    boot_preds.append(m.predict(X))  # X is 200-length\n",
    "boot_preds = np.array(boot_preds)\n",
    "\n",
    "# For each x value, compute the 2.5th and 97.5th percentiles across all 500 predictions.\n",
    "# This gives a 95% bootstrap confidence interval for each point in X.\n",
    "ci_boot = (\n",
    "    np.percentile(boot_preds, 2.5, axis=0),\n",
    "    np.percentile(boot_preds, 97.5, axis=0)\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, alpha=0.3)\n",
    "plt.plot(X['x'], y_hat, color='black', label='Linear Fit')\n",
    "plt.fill_between(X['x'], ci_gauss[0], ci_gauss[1], alpha=0.2, label='Gaussian CI')\n",
    "plt.fill_between(X['x'], ci_boot[0],  ci_boot[1],  alpha=0.3, label='Bootstrap CI')\n",
    "plt.legend()\n",
    "plt.title('Gaussian vs Bootstrap CI')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0532f375",
   "metadata": {},
   "source": [
    "üìå **Observation:** Gaussian CI is narrower than bootstrap CI.\n",
    "üëâ Message: *‚ÄúRisk is underestimated if we assume Gaussian errors.‚Äù*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f76aa4",
   "metadata": {},
   "source": [
    "## Wrap-Up & Communication\n",
    "- Different assumptions change outputs.\n",
    "- Communicate not just results, but how assumptions affect them.\n",
    "- Side-by-side comparisons support transparent risk discussions.\n",
    "- Document assumption dependence and use scenario analysis to build stakeholder trust.\n",
    "\n",
    "### Teaching Tip:\n",
    "End the session with a discussion: \"How would stakeholders react if these assumptions were wrong?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ed98a-ee61-419b-9b92-5c725d41e0b0",
   "metadata": {},
   "source": [
    "## Idea\n",
    "Sampling: Bootstraps your data with replacement (simulate alternative datasets).\n",
    "Preprocessing: Applies your exact cleaning and transformation logic on each sample.\n",
    "Modeling: Fits your model on processed data.\n",
    "Metric extraction: Pulls out whatever summary number you care about (slope, accuracy, etc).\n",
    "CI estimation: Returns a 95% confidence interval reflecting uncertainty from data sampling + pipeline.\n",
    "\n",
    "How to adapt it to your own use:\n",
    "Make preprocess() do your real missing value handling, filtering, normalization, outlier trimming, or whatever assumptions you want.\n",
    "Replace fit_model() with your actual modeling code.\n",
    "Change extract_slope() to compute your final metric or summary statistic.\n",
    "Optionally increase n_bootstrap for tighter CI at the cost of longer computation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
